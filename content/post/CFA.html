---
title: "CFA Model Modification in R lavaan"
author: "Toka"
date: "Oct 29, 2018"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    highlight: tango
    latex_engine: xelatex
    toc: yes
    toc_depth: 3
geometry: margin= 1in
sansfont: Calibri Light
fontsize: 12pt
---



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Confirmatory factor analysis (CFA) is the type of model that extracts common underlying variables from several observed variables and specifying the relationship between the observed and unobserved variables. In this post, I will run a CFA in R using the lavaan package, interpret the output, and make model modifications based on the results.</p>
</div>
<div id="running-a-cfa-in-r" class="section level1">
<h1>Running a CFA in R</h1>
<pre class="r"><code>library(knitr)
library(lavaan)
library(semPlot)
library(data.table)</code></pre>
<p>I will use the Motivations for Alcohol Use Among Adolescents Questionnaire (Cooper, 1994) which consists of four subscales assessing motives for alcohol consumption: Social, Coping, Enhancement, and Conformity. The data are from a large sampel of 848 first year university students that Dr.Paul Tremblay collected years back.First, let’s read in the data. Missing data was coded as ‘-99’.</p>
<p>There are 20 items, and you can find the full item names at the end of this post.</p>
<p>Item format: Likert (1) never or almost never; (2) some of the time; (3) half of the time; (4) most of the time; (5) always or almost always</p>
<p>The four latent variables are created as such: MODEL: social by rC rE rK rN rP; coping by rA rD rF rO rQ; enhanc by rG rI rJ rM rR; conform by rB rH rL rS rT;</p>
<pre class="r"><code>data&lt;-read.csv(&#39;reasons.csv&#39;, na.strings = &#39;-99&#39;)</code></pre>
<p>Let’s look at the first 6 rows of the data. The 20 items were labelled as reasona through reasont.</p>
<pre class="r"><code>head(data)</code></pre>
<pre><code>##   reasona reasonb reasonc reasond reasone reasonf reasong reasonh reasoni
## 1       2       2       4       2       3       3       2       1       3
## 2       1       1       4       1       4       1       5       1       4
## 3       1       1       1       1       1       1       2       1       1
## 4       3       1       4       1       4       3       3       1       2
## 5      NA      NA      NA      NA      NA      NA      NA      NA      NA
## 6       2       2       3       2       3       2       4       1       2
##   reasonj reasonk reasonl reasonm reasonn reasono reasonp reasonq reasonr
## 1       3       4       3       4       4       4       5       2       4
## 2       4       5       1       5       5       4       4       1       5
## 3       1       4       1       2       4       1       4       1       4
## 4       2       4       1       2       4       1       5       1       4
## 5      NA      NA      NA      NA      NA      NA      NA      NA      NA
## 6       1       3       1       4       3       1       4       1       3
##   reasons reasont
## 1       3       2
## 2       1       1
## 3       1       1
## 4       1       1
## 5      NA      NA
## 6       1       1</code></pre>
<div id="specifying-a-cfa-model" class="section level2">
<h2>Specifying a CFA model</h2>
<p>Let’s check the number of rows in the data.</p>
<pre class="r"><code>length(data)</code></pre>
<pre><code>## [1] 20</code></pre>
<p>Now let’s check the number of complete rows to get an idea of how many subject we will need to remove from analysis.</p>
<pre class="r"><code>sum(complete.cases(data))</code></pre>
<pre><code>## [1] 656</code></pre>
<p>I used listwise deletion and removed all subjects that had missing data in any of their 20-item response.</p>
<pre class="r"><code>#listwise deletion of missing data
data&lt;-na.omit(data)
head(data)</code></pre>
<pre><code>##   reasona reasonb reasonc reasond reasone reasonf reasong reasonh reasoni
## 1       2       2       4       2       3       3       2       1       3
## 2       1       1       4       1       4       1       5       1       4
## 3       1       1       1       1       1       1       2       1       1
## 4       3       1       4       1       4       3       3       1       2
## 6       2       2       3       2       3       2       4       1       2
## 7       1       2       2       1       3       2       5       1       5
##   reasonj reasonk reasonl reasonm reasonn reasono reasonp reasonq reasonr
## 1       3       4       3       4       4       4       5       2       4
## 2       4       5       1       5       5       4       4       1       5
## 3       1       4       1       2       4       1       4       1       4
## 4       2       4       1       2       4       1       5       1       4
## 6       1       3       1       4       3       1       4       1       3
## 7       1       4       1       4       4       2       4       1       5
##   reasons reasont
## 1       3       2
## 2       1       1
## 3       1       1
## 4       1       1
## 6       1       1
## 7       1       2</code></pre>
<p>We may want to rename the columns so the structure figure of the model at the end would not look too cramped. The ‘reason’ part of the column names are removed.</p>
<pre class="r"><code>setnames(data, old=c(&#39;reasonc&#39;, &#39;reasone&#39;, &#39;reasonk&#39;, &#39;reasonn&#39; ,&#39;reasonp&#39;,
&#39;reasona&#39;,&#39;reasond&#39;,&#39;reasonf&#39;,&#39;reasono&#39;,&#39;reasonq&#39;,
&#39;reasong&#39;,&#39;reasoni&#39;,&#39;reasonj&#39;,&#39;reasonm&#39;,&#39;reasonr&#39;,
&#39;reasonb&#39;,&#39;reasonh&#39;,&#39;reasonl&#39;,&#39;reasons&#39;,&#39;reasont&#39;), new=c(&#39;c&#39;,&#39;e&#39;,&#39;k&#39;,&#39;n&#39;,&#39;p&#39;,&#39;a&#39;,&#39;d&#39;,&#39;f&#39;,&#39;o&#39;,&#39;q&#39;,&#39;g&#39;,&#39;i&#39;,&#39;j&#39;,&#39;m&#39;,&#39;r&#39;,&#39;b&#39;,&#39;h&#39;,&#39;l&#39;,&#39;s&#39;,&#39;t&#39;))</code></pre>
<p>Let’s take a look at the first 6 rows again.</p>
<pre class="r"><code>head(data)</code></pre>
<pre><code>##   a b c d e f g h i j k l m n o p q r s t
## 1 2 2 4 2 3 3 2 1 3 3 4 3 4 4 4 5 2 4 3 2
## 2 1 1 4 1 4 1 5 1 4 4 5 1 5 5 4 4 1 5 1 1
## 3 1 1 1 1 1 1 2 1 1 1 4 1 2 4 1 4 1 4 1 1
## 4 3 1 4 1 4 3 3 1 2 2 4 1 2 4 1 5 1 4 1 1
## 6 2 2 3 2 3 2 4 1 2 1 3 1 4 3 1 4 1 3 1 1
## 7 1 2 2 1 3 2 5 1 5 1 4 1 4 4 2 4 1 5 1 2</code></pre>
<p>To build a CFA model in lavaan, you’ll save a string with the model details. Each line is one latent factor, with its indicators following the =~ (read this symbol as “is measured by”).</p>
<p>In the code above, there are four latent factors referring to students’ mental ability: social, coping, enhancement, and conformity. The latent factors themselves are never directly measured (that’s what it means for them to be latent), but we’re assuming the 20 variables we did observe are indicators of those latent factors: The social latent factor is measured by c,e,k,n,p. The coping latent factor is measured by a,d,f,o,q. The enhancement factor is measured by g,i,j,m,r. The conformity factor is measured by b,h,l,s,t.</p>
<pre class="r"><code>cfamodel&lt;-&#39;
social=~c+e+k+n+p
coping=~a+d+f+o+q
enhanc=~g+i+j+m+r
conform=~b+h+l+s+t
&#39;</code></pre>
<p>The default estimator for CFA models with continuous indicators is maximum likelihood (ML). Latent factors aren’t measured, so they don’t naturally have any scale. In order to come up with a unique solution, though, the estimator needs to have some scale for them. One solution is to set each latent factor’s scale to the scale of its first indicator — this is lavaan’s default behavior. Another option is to constrain the latent factors to have a mean of 0 and a variance of 1 (i.e. to standardize them). Both approaches will give you equivalent results, without specifying ‘std.lv=TRUE’ when you call cfa(), you will get results from both options.</p>
<p>In the Latent Variables section of the fit summary output, ‘Estimates’ is the loading estimates when the first indicator of each factor was set as marker indicator. ‘Std.lv’ is the loading estimates when the latent factor variances were constrainted to be 1.</p>
<pre class="r"><code>fit&lt;-cfa(cfamodel, data)
summary(fit, fit.measures=TRUE, standardized=T, rsquare=T)</code></pre>
<pre><code>## lavaan 0.6-3 ended normally after 51 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                         46
## 
##   Number of observations                           656
## 
##   Estimator                                         ML
##   Model Fit Test Statistic                     929.971
##   Degrees of freedom                               164
##   P-value (Chi-square)                           0.000
## 
## Model test baseline model:
## 
##   Minimum Function Test Statistic             7370.958
##   Degrees of freedom                               190
##   P-value                                        0.000
## 
## User model versus baseline model:
## 
##   Comparative Fit Index (CFI)                    0.893
##   Tucker-Lewis Index (TLI)                       0.876
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -16312.578
##   Loglikelihood unrestricted model (H1)     -15847.592
## 
##   Number of free parameters                         46
##   Akaike (AIC)                               32717.156
##   Bayesian (BIC)                             32923.520
##   Sample-size adjusted Bayesian (BIC)        32777.469
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.084
##   90 Percent Confidence Interval          0.079  0.090
##   P-value RMSEA &lt;= 0.05                          0.000
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.105
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                             Standard
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   social =~                                                             
##     c                 1.000                               0.962    0.727
##     e                 0.698    0.055   12.803    0.000    0.672    0.512
##     k                 1.237    0.053   23.173    0.000    1.190    0.912
##     n                 1.264    0.055   23.107    0.000    1.217    0.909
##     p                 0.637    0.048   13.399    0.000    0.613    0.536
##   coping =~                                                             
##     a                 1.000                               0.719    0.855
##     d                 1.057    0.045   23.666    0.000    0.760    0.786
##     f                 0.944    0.042   22.535    0.000    0.679    0.760
##     o                 0.645    0.078    8.250    0.000    0.464    0.328
##     q                 1.150    0.041   27.791    0.000    0.827    0.882
##   enhanc =~                                                             
##     g                 1.000                               1.131    0.801
##     i                 0.940    0.045   21.014    0.000    1.063    0.758
##     j                 0.602    0.043   14.010    0.000    0.681    0.540
##     m                 0.996    0.041   24.465    0.000    1.127    0.854
##     r                 0.912    0.040   22.832    0.000    1.031    0.809
##   conform =~                                                            
##     b                 1.000                               0.439    0.537
##     h                 0.638    0.059   10.746    0.000    0.280    0.555
##     l                 1.542    0.125   12.356    0.000    0.677    0.698
##     s                 1.242    0.099   12.514    0.000    0.545    0.715
##     t                 1.833    0.137   13.391    0.000    0.805    0.852
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   social ~~                                                             
##     coping            0.216    0.032    6.708    0.000    0.312    0.312
##     enhanc            0.902    0.072   12.550    0.000    0.829    0.829
##     conform           0.164    0.023    7.036    0.000    0.387    0.387
##   coping ~~                                                             
##     enhanc            0.254    0.038    6.719    0.000    0.313    0.313
##     conform           0.104    0.016    6.346    0.000    0.328    0.328
##   enhanc ~~                                                             
##     conform           0.129    0.025    5.223    0.000    0.259    0.259
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .c                 0.826    0.050   16.560    0.000    0.826    0.471
##    .e                 1.268    0.072   17.627    0.000    1.268    0.738
##    .k                 0.287    0.027   10.800    0.000    0.287    0.168
##    .n                 0.312    0.028   11.048    0.000    0.312    0.174
##    .p                 0.933    0.053   17.563    0.000    0.933    0.713
##    .a                 0.190    0.015   12.541    0.000    0.190    0.269
##    .d                 0.357    0.024   14.896    0.000    0.357    0.382
##    .f                 0.336    0.022   15.408    0.000    0.336    0.422
##    .o                 1.785    0.100   17.881    0.000    1.785    0.892
##    .q                 0.195    0.018   11.009    0.000    0.195    0.222
##    .g                 0.712    0.048   14.751    0.000    0.712    0.358
##    .i                 0.834    0.053   15.594    0.000    0.834    0.425
##    .j                 1.128    0.065   17.356    0.000    1.128    0.709
##    .m                 0.471    0.036   13.052    0.000    0.471    0.271
##    .r                 0.561    0.039   14.564    0.000    0.561    0.346
##    .b                 0.477    0.028   16.796    0.000    0.477    0.712
##    .h                 0.176    0.011   16.659    0.000    0.176    0.692
##    .l                 0.482    0.032   14.879    0.000    0.482    0.512
##    .s                 0.284    0.020   14.525    0.000    0.284    0.488
##    .t                 0.245    0.026    9.386    0.000    0.245    0.274
##     social            0.926    0.088   10.565    0.000    1.000    1.000
##     coping            0.517    0.039   13.204    0.000    1.000    1.000
##     enhanc            1.279    0.106   12.019    0.000    1.000    1.000
##     conform           0.193    0.028    6.878    0.000    1.000    1.000
## 
## R-Square:
##                    Estimate
##     c                 0.529
##     e                 0.262
##     k                 0.832
##     n                 0.826
##     p                 0.287
##     a                 0.731
##     d                 0.618
##     f                 0.578
##     o                 0.108
##     q                 0.778
##     g                 0.642
##     i                 0.575
##     j                 0.291
##     m                 0.729
##     r                 0.654
##     b                 0.288
##     h                 0.308
##     l                 0.488
##     s                 0.512
##     t                 0.726</code></pre>
</div>
<div id="check-fit-indices" class="section level2">
<h2>Check fit indices</h2>
<p><b>CFI (Comparative fit index)</b>: Measures whether the model fits the data better than a more restricted baseline model. Higher is better, with okay fit &gt; .9.</p>
<p><b>TLI (Tucker-Lewis index)</b>: Similar to CFI, but it penalizes overly complex models (making it more conservative than CFI). Measures whether the model fits the data better than a more restricted baseline model. Higher is better, with okay fit &gt; .9.</p>
<p><b>RMSEA (Root mean square error of approximation)</b>: The “error of approximation” refers to residuals. Instead of comparing to a baseline model, it measures how closely the model reproduces data patterns (i.e. the covariances among indicators). Lower is better. It comes with a 90%CI in lavaan and other major SEM software, so that’s often reported along with it.</p>
<p>The p-value printed with it tests the hypothesis that RMSEA is less than or equal to .06 (a cutoff sometimes used for “close” fit); here, our RMSEA is greater than .05 (it’s .092, with a 90%CI from .07 to .11), so the p-value is unsurprisingly significant, telling us that RMSEA is NOT less than or equal to .05. This p-value is sometimes called “the p of Close Fit” or “PCLOSE” in other software. If it is greater than α (usually set at .05), then it is typical to report that the model has “close fit” according to the RMSEA.</p>
<p>Also note that Good model fit does not make a good model. The model needs to be solid theoretically before you estimate it.</p>
</div>
<div id="residual-correlations" class="section level2">
<h2>residual correlations</h2>
<p>The goal of the CFA is to explain relationships among the observed variables by specifying a latent structure connecting them.</p>
<p>For example, in our model, we’re saying that c,e,k,n, and p are all correlated because they’re different ways to measure the same basic underlying motivation, social. And although c and b measure different motivations (social andd conformity, respectively), we would still expect them to have some correlation because individuals latent social and conformity motivations are correlated.</p>
<p>Because our model implies expected relationships among the observed variables, one way to examine its performance is to look at the difference between the correlation matrix the model expects and the actual, observed correlation matrix you get from your raw data. These (or the equivalent based on covariance matrices) are the residuals of an SEM model. Any large residual correlations between variables suggests that there’s something about the relationship between those two indicators that the model is not adequately capturing.</p>
<pre class="r"><code>correl&lt;- residuals(fit, type=&#39;cor&#39;)
correl</code></pre>
<pre><code>## $type
## [1] &quot;cor.bollen&quot;
## 
## $cov
##   c      e      k      n      p      a      d      f      o      q     
## c  0.000                                                               
## e  0.151  0.000                                                        
## k -0.009 -0.008  0.000                                                 
## n  0.005 -0.039  0.003  0.000                                          
## p  0.001  0.067 -0.023  0.002  0.000                                   
## a  0.022  0.004 -0.058 -0.043 -0.077  0.000                            
## d  0.106  0.083 -0.024  0.002 -0.040  0.001  0.000                     
## f  0.076  0.045 -0.009  0.014  0.015  0.000  0.013  0.000              
## o  0.426  0.384  0.502  0.516  0.248 -0.072  0.023  0.009  0.000       
## q  0.008 -0.026 -0.031 -0.012 -0.048  0.015 -0.012 -0.009 -0.015  0.000
## g -0.076 -0.093 -0.041 -0.064 -0.044 -0.007  0.009  0.082  0.315  0.018
## i -0.030  0.007  0.046  0.003 -0.008 -0.089 -0.018 -0.007  0.395 -0.047
## j -0.004 -0.004 -0.008 -0.021 -0.003  0.066  0.108  0.140  0.269  0.121
## m -0.080 -0.078 -0.002  0.001  0.038 -0.052 -0.015 -0.004  0.418 -0.007
## r -0.006 -0.024  0.077  0.065  0.137 -0.080 -0.046  0.016  0.367 -0.038
## b  0.063  0.119 -0.013  0.024  0.020  0.058  0.135  0.020  0.181  0.068
## h -0.034  0.026 -0.119 -0.122 -0.083  0.004  0.080  0.001  0.069 -0.012
## l  0.099  0.196  0.063  0.054  0.011 -0.061  0.071 -0.069  0.260 -0.004
## s  0.027  0.112 -0.007  0.007  0.019 -0.040  0.040  0.001  0.274  0.035
## t  0.050  0.139 -0.051 -0.009 -0.030 -0.094 -0.004 -0.006  0.246 -0.017
##   g      i      j      m      r      b      h      l      s      t     
## c                                                                      
## e                                                                      
## k                                                                      
## n                                                                      
## p                                                                      
## a                                                                      
## d                                                                      
## f                                                                      
## o                                                                      
## q                                                                      
## g  0.000                                                               
## i  0.001  0.000                                                        
## j  0.007  0.102  0.000                                                 
## m  0.057 -0.029 -0.029  0.000                                          
## r -0.029 -0.004 -0.046 -0.011  0.000                                   
## b -0.048  0.021 -0.035 -0.020  0.014  0.000                            
## h -0.117 -0.025 -0.050 -0.093 -0.092  0.104  0.000                     
## l -0.022  0.071  0.072  0.050  0.045  0.007 -0.025  0.000              
## s -0.029  0.051  0.015  0.041  0.042 -0.051 -0.058  0.018  0.000       
## t -0.063  0.058  0.012 -0.019  0.017 -0.018  0.025 -0.013  0.017  0.000</code></pre>
<p>Keep an eye out for residual correlations larger than about .1. These residuals mostly look really good, with the few exceptions, most strikingly item ‘o’ is highly correlated with many other items. The RMSEA discussed above is based on these residual correlations, so the deviations we’re seeing here are what’s driving the RMSEA value we saw above.</p>
<p>Modification indices tell you how model fit would change if you added new parameters to the model. Since your CFA model should not be exploratory (i.e. you should know what parameters you want to include in the model before you begin), modification indices can be dangerous. If you make the changes they suggest, you run a serious risk of over-fitting your data and reducing the generalizability of your results.</p>
<p>Instead, I recommend using modification indices mostly as another description of the places where your model is not fitting well, like examining the residuals. In the code below, I’ve sorted the modification indices by mi which is an estimate of how much the model fit would improve if each parameter were added. You can see from the output below that the top modification indices are all for item o, suggesting that those variables are involved in some covariances that aren’t well captured by the current model structure. In particular, the top modification index is for a factor loading from social or enhancement to o (i.e., feel more self-confident); it’s useful to know that there is some extra covariance between o and the social and enhancement motivation. Taken together, this all suggests to me that o is not quite adhering to the expected pattern from the model.</p>
<pre class="r"><code>kable(modificationindices(fit, sort. =T, minimum.value = 30))</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">lhs</th>
<th align="left">op</th>
<th align="left">rhs</th>
<th align="right">mi</th>
<th align="right">epc</th>
<th align="right">sepc.lv</th>
<th align="right">sepc.all</th>
<th align="right">sepc.nox</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>54</td>
<td align="left">social</td>
<td align="left">=~</td>
<td align="left">o</td>
<td align="right">250.23884</td>
<td align="right">0.9510768</td>
<td align="right">0.9153574</td>
<td align="right">0.6472184</td>
<td align="right">0.6472184</td>
</tr>
<tr class="even">
<td>89</td>
<td align="left">enhanc</td>
<td align="left">=~</td>
<td align="left">o</td>
<td align="right">188.94630</td>
<td align="right">0.7128527</td>
<td align="right">0.8060697</td>
<td align="right">0.5699447</td>
<td align="right">0.5699447</td>
</tr>
<tr class="odd">
<td>104</td>
<td align="left">conform</td>
<td align="left">=~</td>
<td align="left">o</td>
<td align="right">80.92223</td>
<td align="right">1.2539919</td>
<td align="right">0.5507724</td>
<td align="right">0.3894326</td>
<td align="right">0.3894326</td>
</tr>
<tr class="even">
<td>258</td>
<td align="left">g</td>
<td align="left">~~</td>
<td align="left">m</td>
<td align="right">51.35919</td>
<td align="right">0.2455255</td>
<td align="right">0.2455255</td>
<td align="right">0.4239067</td>
<td align="right">0.4239067</td>
</tr>
<tr class="odd">
<td>111</td>
<td align="left">c</td>
<td align="left">~~</td>
<td align="left">e</td>
<td align="right">48.45098</td>
<td align="right">0.2960064</td>
<td align="right">0.2960064</td>
<td align="right">0.2892879</td>
<td align="right">0.2892879</td>
</tr>
<tr class="even">
<td>60</td>
<td align="left">social</td>
<td align="left">=~</td>
<td align="left">r</td>
<td align="right">44.01770</td>
<td align="right">0.5463015</td>
<td align="right">0.5257842</td>
<td align="right">0.4125562</td>
<td align="right">0.4125562</td>
</tr>
<tr class="odd">
<td>56</td>
<td align="left">social</td>
<td align="left">=~</td>
<td align="left">g</td>
<td align="right">37.90340</td>
<td align="right">-0.5639024</td>
<td align="right">-0.5427241</td>
<td align="right">-0.3846826</td>
<td align="right">-0.3846826</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="model-modification" class="section level1">
<h1>Model modification</h1>
<div id="modified-model-1" class="section level2">
<h2>Modified model 1</h2>
<p>As we have seen that o was a problematic item, thus we will remove it in this model specification.</p>
<pre class="r"><code>cfamodel_2&lt;-&#39;
social=~c+e+k+n+p
coping=~a+d+f+q
enhanc=~g+i+j+m+r
conform=~b+h+l+s+t
&#39;

fit2&lt;-cfa(cfamodel_2, data)</code></pre>
<pre class="r"><code>#summary(fit2, fit.measures=TRUE, standardized=T, rsquare=T)
fit2</code></pre>
<pre><code>## lavaan 0.6-3 ended normally after 47 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                         44
## 
##   Number of observations                           656
## 
##   Estimator                                         ML
##   Model Fit Test Statistic                     555.783
##   Degrees of freedom                               146
##   P-value (Chi-square)                           0.000</code></pre>
<pre class="r"><code>kable(modificationindices(fit2, sort. =T, minimum.value = 30))</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">lhs</th>
<th align="left">op</th>
<th align="left">rhs</th>
<th align="right">mi</th>
<th align="right">epc</th>
<th align="right">sepc.lv</th>
<th align="right">sepc.all</th>
<th align="right">sepc.nox</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>234</td>
<td align="left">g</td>
<td align="left">~~</td>
<td align="left">m</td>
<td align="right">51.48188</td>
<td align="right">0.2458728</td>
<td align="right">0.2458728</td>
<td align="right">0.4243857</td>
<td align="right">0.4243857</td>
</tr>
<tr class="even">
<td>106</td>
<td align="left">c</td>
<td align="left">~~</td>
<td align="left">e</td>
<td align="right">48.48929</td>
<td align="right">0.2961850</td>
<td align="right">0.2961850</td>
<td align="right">0.2893912</td>
<td align="right">0.2893912</td>
</tr>
<tr class="odd">
<td>57</td>
<td align="left">social</td>
<td align="left">=~</td>
<td align="left">r</td>
<td align="right">44.01533</td>
<td align="right">0.5464029</td>
<td align="right">0.5257776</td>
<td align="right">0.4125512</td>
<td align="right">0.4125512</td>
</tr>
<tr class="even">
<td>53</td>
<td align="left">social</td>
<td align="left">=~</td>
<td align="left">g</td>
<td align="right">37.97119</td>
<td align="right">-0.5645913</td>
<td align="right">-0.5432794</td>
<td align="right">-0.3850761</td>
<td align="right">-0.3850761</td>
</tr>
</tbody>
</table>
</div>
<div id="modified-model-2" class="section level2">
<h2>Modified model 2</h2>
<p>Add error covariances between g and m</p>
<pre class="r"><code>cfamodel_3&lt;-&#39;
social=~c+e+k+n+p
coping=~a+d+f+q
enhanc=~g+i+j+m+r
conform=~b+h+l+s+t
g~~m
&#39;

fit3&lt;-cfa(cfamodel_3, data)
summary(fit3, fit.measures=TRUE, standardized=T, rsquare=T)</code></pre>
<pre><code>## lavaan 0.6-3 ended normally after 50 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                         45
## 
##   Number of observations                           656
## 
##   Estimator                                         ML
##   Model Fit Test Statistic                     508.027
##   Degrees of freedom                               145
##   P-value (Chi-square)                           0.000
## 
## Model test baseline model:
## 
##   Minimum Function Test Statistic             6930.370
##   Degrees of freedom                               171
##   P-value                                        0.000
## 
## User model versus baseline model:
## 
##   Comparative Fit Index (CFI)                    0.946
##   Tucker-Lewis Index (TLI)                       0.937
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -15163.684
##   Loglikelihood unrestricted model (H1)     -14909.671
## 
##   Number of free parameters                         45
##   Akaike (AIC)                               30417.369
##   Bayesian (BIC)                             30619.246
##   Sample-size adjusted Bayesian (BIC)        30476.371
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.062
##   90 Percent Confidence Interval          0.056  0.068
##   P-value RMSEA &lt;= 0.05                          0.000
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.053
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                             Standard
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   social =~                                                             
##     c                 1.000                               0.961    0.726
##     e                 0.699    0.055   12.802    0.000    0.672    0.512
##     k                 1.240    0.054   23.165    0.000    1.192    0.913
##     n                 1.265    0.055   23.055    0.000    1.216    0.908
##     p                 0.639    0.048   13.433    0.000    0.614    0.537
##   coping =~                                                             
##     a                 1.000                               0.724    0.861
##     d                 1.046    0.044   23.745    0.000    0.758    0.784
##     f                 0.936    0.041   22.629    0.000    0.678    0.759
##     q                 1.143    0.041   28.067    0.000    0.828    0.883
##   enhanc =~                                                             
##     g                 1.000                               1.058    0.750
##     i                 1.015    0.053   19.257    0.000    1.074    0.767
##     j                 0.647    0.048   13.401    0.000    0.684    0.542
##     m                 1.014    0.040   25.657    0.000    1.073    0.814
##     r                 0.996    0.048   20.783    0.000    1.054    0.827
##   conform =~                                                            
##     b                 1.000                               0.439    0.536
##     h                 0.638    0.059   10.737    0.000    0.280    0.555
##     l                 1.544    0.125   12.345    0.000    0.677    0.698
##     s                 1.243    0.099   12.503    0.000    0.545    0.715
##     t                 1.835    0.137   13.376    0.000    0.805    0.852
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##  .g ~~                                                                  
##    .m                 0.245    0.040    6.172    0.000    0.245    0.343
##   social ~~                                                             
##     coping            0.201    0.032    6.271    0.000    0.288    0.288
##     enhanc            0.870    0.071   12.283    0.000    0.855    0.855
##     conform           0.163    0.023    7.030    0.000    0.387    0.387
##   coping ~~                                                             
##     enhanc            0.222    0.036    6.156    0.000    0.289    0.289
##     conform           0.100    0.016    6.141    0.000    0.314    0.314
##   enhanc ~~                                                             
##     conform           0.129    0.024    5.419    0.000    0.277    0.277
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .c                 0.828    0.050   16.588    0.000    0.828    0.473
##    .e                 1.268    0.072   17.632    0.000    1.268    0.737
##    .k                 0.284    0.026   10.822    0.000    0.284    0.167
##    .n                 0.315    0.028   11.228    0.000    0.315    0.176
##    .p                 0.931    0.053   17.565    0.000    0.931    0.711
##    .a                 0.183    0.015   12.183    0.000    0.183    0.258
##    .d                 0.360    0.024   14.941    0.000    0.360    0.385
##    .f                 0.338    0.022   15.430    0.000    0.338    0.424
##    .q                 0.193    0.018   10.896    0.000    0.193    0.220
##    .g                 0.871    0.059   14.866    0.000    0.871    0.437
##    .i                 0.809    0.054   15.002    0.000    0.809    0.412
##    .j                 1.124    0.065   17.223    0.000    1.124    0.706
##    .m                 0.589    0.043   13.544    0.000    0.589    0.338
##    .r                 0.513    0.038   13.326    0.000    0.513    0.316
##    .b                 0.477    0.028   16.798    0.000    0.477    0.712
##    .h                 0.176    0.011   16.658    0.000    0.176    0.692
##    .l                 0.482    0.032   14.875    0.000    0.482    0.512
##    .s                 0.284    0.020   14.519    0.000    0.284    0.488
##    .t                 0.244    0.026    9.360    0.000    0.244    0.274
##     social            0.924    0.088   10.549    0.000    1.000    1.000
##     coping            0.525    0.039   13.343    0.000    1.000    1.000
##     enhanc            1.120    0.104   10.732    0.000    1.000    1.000
##     conform           0.193    0.028    6.870    0.000    1.000    1.000
## 
## R-Square:
##                    Estimate
##     c                 0.527
##     e                 0.263
##     k                 0.833
##     n                 0.824
##     p                 0.289
##     a                 0.742
##     d                 0.615
##     f                 0.576
##     q                 0.780
##     g                 0.563
##     i                 0.588
##     j                 0.294
##     m                 0.662
##     r                 0.684
##     b                 0.288
##     h                 0.308
##     l                 0.488
##     s                 0.512
##     t                 0.726</code></pre>
</div>
</div>
<div id="graph-final-model-structure" class="section level1">
<h1>Graph final model structure</h1>
<pre class="r"><code>semPaths(fit3, &#39;std&#39;, layout=&#39;tree&#39;)</code></pre>
<p><img src="/post/CFA_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>There are 20 items labelled rA rB rC rD rE rF rG rH rI rJ rK rL rM rN rO rP rQ rR rS rT (and this is the order of the variables in the data file.<br> Reason a - forget worries<br> Reason b - friends pressure<br> Reason c - help enjoy party<br> Reason d - relieve feeling depressed or nervous<br> Reason e - to be sociable<br> Reason f - to cheer up<br> Reason g - like the feeling<br> Reason h - avoid being teased<br> Reason i - it is exciting<br> Reason j - get high<br> Reason k - makes social gatherings more fun<br> Reason l - fit in with group<br> Reason m - gives pleasant feeling<br> Reason n - improves parties<br> Reason o - feel more self-confident<br> Reason p – celebrate special occasions<br> Reason q - forget about problems<br> Reason r - it is fun<br> Reason s - to be liked<br> Reason t - so will not feel left out<br></p>
</div>
